# Running BusinessViews project options


After building the jar of this project, it can be run using several options or arguments:

* It can be given unbounded <source>... (source names) arguments for building all the business views
underlying a given source name.
* -p or --partitions <appName> is an option that you can use to generate the latest partitions of all the data source files 
 on HDFS. The option's parameter can only have 2 values, 'bigMatching' or 'buildThirdParties'
* -s or --hive-schema <database> is an option that takes a database name as argument. You can use it to print in the
standard output the hive business views creation schema statements for the sources <source>... given as argument.



An example spark-submit to run the application jar for building avox business views would be :

```
spark-submit --master yarn
              --verbose
              --deploy-mode client
              --queue CBS
              --class sg.cbs.bv.Main
              --jars /applis/hadd/haddadm/bsc/cbs/usecases/ralph/schemas
              businessviews-0.1-SNAPSHOT-spark.jar avox
```
An example spark-submit to run the application jar for printing avox and rct business views schemas on the database cbs
would be:


```
spark-submit --master yarn
              --verbose
              --deploy-mode client
              --queue CBS
              --class sg.cbs.bv.Main
              --jars /applis/hadd/haddadm/bsc/cbs/usecases/ralph/schemas
              businessviews-0.1-SNAPSHOT-spark.jar avox rct --hive-schema cbs
```
The directory schemas/ added to the classpath in the --jars option holds the configuration files needed to locate
the data generated by the Enriched Data project on the HDFS.
When running your tests on the driver node on dev for instance, you need to create this directory and add all the
necessary configuration files.

# Adding a new Source

When adding a new source, you need to follow the steps below:

* Update the ViewBuilder class with the new source and underlying business views.
* Update the HiveSchemaCreator class with the new source in order to add the schemas of its underlying business
views to the schema generation process.
* Update the BigmatchingConfigWriter datasets variable if the new source is used in the matching process. The value
to be added to the datasets list should be the name of the source hive table generated by the Enriched Data project.
* Create a class inheriting from the BusinessView class and implement the process() method using the
DataFrameTransformer framework and the implemented UDFs in the CommonUdf class.
* Implement the necessary tests for the created class  above.
